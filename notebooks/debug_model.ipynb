{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d4e381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 15:07:41.020005: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.keras import Model, Sequential, layers, regularizers, optimizers\n",
    "from colorama import Fore, Style\n",
    "import pickle\n",
    "from typing import Tuple\n",
    "import os\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4f99faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(X:np.ndarray):\n",
    "    \"\"\"\n",
    "    Accepts raw source_code as input and tokenizes using TF-IDF\n",
    "    :return: returns the preprocessed X and the vocab_size\n",
    "    \"\"\"\n",
    "    print(Fore.BLUE + \"\\nTokenizes source code...\" + Style.RESET_ALL)\n",
    "    # Initialize Tokenizer and fit to X\n",
    "    tk = Tokenizer()\n",
    "    tk.fit_on_texts(X)\n",
    "\n",
    "    # Define vocab size\n",
    "    vocab_size = len(tk.word_index)\n",
    "    print(f'There are {vocab_size} different words in your corpus')\n",
    "\n",
    "    # Transform to sequences\n",
    "    X_token = tk.texts_to_sequences(X)\n",
    "\n",
    "    # Pad inputs\n",
    "    X_pad = pad_sequences(X_token, dtype='float32', padding='post', value=0)\n",
    "    print(\"\\n✅ Source code tokenized\")\n",
    "    return X_pad, vocab_size\n",
    "\n",
    "\n",
    "\n",
    "def label_encode(y:np.ndarray)->np.ndarray:\n",
    "    target_encoder = LabelEncoder().fit(y)\n",
    "    target_encoded = target_encoder.transform(y)\n",
    "    \n",
    "    target_cat = to_categorical(target_encoded, num_classes = len(np.unique(target_encoded)))\n",
    "    \n",
    "    return target_cat\n",
    "\n",
    "\n",
    "\n",
    "def initialize_model(X_pad: np.ndarray,\n",
    "                     y = np.ndarray,\n",
    "                     vocab_size = None) -> Model:\n",
    "    \"\"\"\n",
    "    Initialize the CNN with random weights\n",
    "    \"\"\"\n",
    "\n",
    "    print(Fore.BLUE + \"\\nInitialize model...\" + Style.RESET_ALL)\n",
    "\n",
    "    if vocab_size is not None:\n",
    "        input_dim = vocab_size\n",
    "    else:\n",
    "        print(f\"\\n❌ vocab size needed to define input dimension. Please insert the vocab size returned by the tokenize function.\")\n",
    "        return None\n",
    "\n",
    "    input_length = X_pad.shape[1]\n",
    "\n",
    "    print(f'input_dim = {input_dim}')\n",
    "    print(f'input_length = {input_length}')\n",
    "\n",
    "    model = Sequential([\n",
    "        layers.Embedding(input_dim=input_dim, input_length=input_length, output_dim=256, mask_zero=True),\n",
    "        layers.Conv1D(128, kernel_size=3),\n",
    "        layers.MaxPool1D(pool_size = (4)),\n",
    "        layers.Conv1D(128, kernel_size=5),\n",
    "        layers.MaxPool1D(pool_size = (4)),\n",
    "        layers.Conv1D(128, kernel_size=7),\n",
    "        layers.MaxPool1D(pool_size = (4)),\n",
    "        layers.Conv1D(128, kernel_size=9),\n",
    "        layers.MaxPool1D(pool_size = (4)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(y.shape[1], activation=\"softmax\"),  # check if we need to input the number of categories in softmax\n",
    "        ])\n",
    "\n",
    "    print(\"\\n✅ Model initialized. Summary:\")\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def compile_model(model: Model) -> Model:\n",
    "    \"\"\"\n",
    "    Compile the CNN\n",
    "    \"\"\"\n",
    "    print(Fore.BLUE + \"\\nCompile model...\" + Style.RESET_ALL)\n",
    "    es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print(\"\\n✅ Model compiled\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model: Model,\n",
    "                X_pad: np.ndarray,\n",
    "                y: np.ndarray,\n",
    "                batch_size=64,\n",
    "                epochs=200,\n",
    "                patience=2,\n",
    "                verbose=0,\n",
    "                validation_split=0.2\n",
    "                ) -> Tuple[Model, dict]:\n",
    "    \"\"\"\n",
    "    Fit model and return a tuple (fitted_model, history)\n",
    "    \"\"\"\n",
    "\n",
    "    print(Fore.BLUE + \"\\nTrain model...\" + Style.RESET_ALL)\n",
    "    breakpoint()\n",
    "    # TODO Discuss: should we use monitor?\n",
    "    es = EarlyStopping(patience=10,\n",
    "                       restore_best_weights=True,\n",
    "                       # monitor=\"val_loss\"\n",
    "                       )\n",
    "\n",
    "    history = model.fit(X_pad,\n",
    "                      y,\n",
    "                      epochs=epochs,\n",
    "                      batch_size=batch_size,\n",
    "                      verbose=verbose,\n",
    "                      validation_split=validation_split,\n",
    "                      callbacks=[es])\n",
    "\n",
    "    print(f\"\\n✅ Model trained ({len(X_pad)} rows)\")\n",
    "\n",
    "    return model, history\n",
    "\n",
    "\n",
    "def predict(code:str)-> np.ndarray:\n",
    "    \"\"\"\n",
    "    Accepts a piece of code as an input, to predict its author as a return.\n",
    "    :param code: a given peace of code.\n",
    "    :return: returns an array containing one or more predictions of authors for the given peaces of code\n",
    "    \"\"\"\n",
    "    print(Fore.BLUE + \"\\nPredict author...\" + Style.RESET_ALL)\n",
    "    # Load model\n",
    "    model = pickle.load(open(\"model.pkl\",\"rb\"))\n",
    "\n",
    "    # predict with model\n",
    "    prediction = model.predict_proba(code)\n",
    "\n",
    "    # TODO inverse_transform the result\n",
    "    print(f\"\\n✅ Prediction done!\")\n",
    "    return prediction\n",
    "    # return prediction_inversed\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model: Model,\n",
    "                   X: np.ndarray,\n",
    "                   y: np.ndarray,\n",
    "                   batch_size=64) -> Tuple[Model, dict]:\n",
    "    \"\"\"\n",
    "    Evaluate trained model performance on dataset\n",
    "    # TODO are the metrics rigt? Which one should we used?\n",
    "    \"\"\"\n",
    "\n",
    "    print(Fore.BLUE + f\"\\nEvaluate model on {len(X)} rows...\" + Style.RESET_ALL)\n",
    "\n",
    "    if model is None:\n",
    "        print(f\"\\n❌ no model to evaluate\")\n",
    "        return None\n",
    "\n",
    "    metrics = model.evaluate(\n",
    "        x=X,\n",
    "        y=y,\n",
    "        batch_size=batch_size,\n",
    "        verbose=1,\n",
    "        # callbacks=None,\n",
    "        return_dict=True)\n",
    "\n",
    "    loss = metrics[\"loss\"]\n",
    "    mae = metrics[\"mae\"]\n",
    "\n",
    "    print(f\"\\n✅ Model evaluated: loss {round(loss, 2)} mae {round(mae, 2)}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def save_model(model: Model = None,\n",
    "               params: dict = None,\n",
    "               metrics: dict = None) -> None:\n",
    "    \"\"\"\n",
    "    persist trained model, params and metrics\n",
    "    \"\"\"\n",
    "\n",
    "    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    print(Fore.BLUE + \"\\nSave model to local disk...\" + Style.RESET_ALL)\n",
    "\n",
    "    # save params\n",
    "    if params is not None:\n",
    "        params_path = os.path.join('params.pkl', \"params\", timestamp + \".pickle\")\n",
    "        print(f\"- params path: {params_path}\")\n",
    "        with open(params_path, \"wb\") as file:\n",
    "            pickle.dump(params, file)\n",
    "\n",
    "    # save metrics\n",
    "    if metrics is not None:\n",
    "        metrics_path = os.path.join('metrics.pkl', \"metrics\", timestamp + \".pickle\")\n",
    "        print(f\"- metrics path: {metrics_path}\")\n",
    "        with open(metrics_path, \"wb\") as file:\n",
    "            pickle.dump(metrics, file)\n",
    "\n",
    "    # save model\n",
    "    if model is not None:\n",
    "        model_path = os.path.join('model.pkl', \"models\", timestamp)\n",
    "        print(f\"- model path: {model_path}\")\n",
    "        model.save(model_path)\n",
    "\n",
    "    print(\"\\n✅ Data saved locally\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# TODO not working yet - check paths?\n",
    "def load_model(save_copy_locally=False) -> Model:\n",
    "    \"\"\"\n",
    "    load the latest saved model, return None if no model found\n",
    "    \"\"\"\n",
    "    print(Fore.BLUE + \"\\nLoad model from local disk...\" + Style.RESET_ALL)\n",
    "\n",
    "    # get latest model version\n",
    "    model_directory = os.path.join(\"models\")\n",
    "\n",
    "    results = glob.glob(f\"{model_directory}/*\")\n",
    "    if not results:\n",
    "        return None\n",
    "\n",
    "    model_path = sorted(results)[-1]\n",
    "    print(f\"- path: {model_path}\")\n",
    "\n",
    "    model = models.load_model(model_path)\n",
    "    print(\"\\n✅ model loaded from disk\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "851bd97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data= pd.read_csv('../raw_data/preprocessed_dataset.csv')[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "223f0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"code_source\"]\n",
    "y = label_encode(y = data[\"username\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1098c165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 24)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78319439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc047f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Tokenizes source code...\u001b[0m\n",
      "There are 4365 different words in your corpus\n",
      "\n",
      "✅ Source code tokenized\n",
      "[[ 11. 135.  11. ...   0.   0.   0.]\n",
      " [ 11. 119.  11. ...   0.   0.   0.]\n",
      " [ 11. 119.  11. ...   0.   0.   0.]\n",
      " ...\n",
      " [ 11. 119.  11. ...   0.   0.   0.]\n",
      " [ 11. 119.  11. ...   0.   0.   0.]\n",
      " [ 11. 119.  11. ...   0.   0.   0.]]\n",
      "4365\n"
     ]
    }
   ],
   "source": [
    "data_tokenized, vocab_size = tokenize(X = X)\n",
    "print(data_tokenized)\n",
    "print(vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0d4d8687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 24)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f1f297c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Initialize model...\u001b[0m\n",
      "input_dim = 4365\n",
      "input_length = 2652\n",
      "\n",
      "✅ Model initialized. Summary:\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 2652, 256)         1117440   \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 2650, 128)         98432     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 662, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 658, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 164, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 158, 128)          114816    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 31, 128)           147584    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 24)                21528     \n",
      "=================================================================\n",
      "Total params: 1,581,848\n",
      "Trainable params: 1,581,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model(X_pad=data_tokenized,\n",
    "                         y = y,\n",
    "                         vocab_size = vocab_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cca829e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Compile model...\u001b[0m\n",
      "\n",
      "✅ Model compiled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x139b151f0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compile_model(model = model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d4f9025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "Train model...\u001b[0m\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_3/embedding_3/embedding_lookup' defined at (most recent call last):\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/xx/tt65cl5915g65mpfmwy5nk8h0000gn/T/ipykernel_10534/3232910807.py\", line 1, in <module>\n      model, history = train_model(model = model,\n    File \"/var/folders/xx/tt65cl5915g65mpfmwy5nk8h0000gn/T/ipykernel_10534/4016102854.py\", line 113, in train_model\n      history = model.fit(X_pad,\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1218, in fit\n      val_logs = self.evaluate(\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1497, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1327, in test_function\n      return step_function(self, iterator)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1318, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1311, in run_step\n      outputs = model.test_step(data)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1270, in test_step\n      y_pred = self(x, training=False)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1044, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\", line 379, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\", line 419, in call\n      return self._run_internal_graph(\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\", line 555, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1044, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/layers/embeddings.py\", line 191, in call\n      out = embedding_ops.embedding_lookup_v2(self.embeddings, inputs)\nNode: 'sequential_3/embedding_3/embedding_lookup'\nindices[3,122] = 4365 is not in [0, 4365)\n\t [[{{node sequential_3/embedding_3/embedding_lookup}}]] [Op:__inference_test_function_3758]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                \u001b[49m\u001b[43mX_pad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_tokenized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [39], line 113\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, X_pad, y, batch_size, epochs, patience, verbose, validation_split)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# TODO Discuss: should we use monitor?\u001b[39;00m\n\u001b[1;32m    108\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m    109\u001b[0m                    restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    110\u001b[0m                    \u001b[38;5;66;03m# monitor=\"val_loss\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m                    )\n\u001b[0;32m--> 113\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_pad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                  \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ Model trained (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_pad)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1218\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1205\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1206\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1207\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1216\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1217\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1218\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1230\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m   1231\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1497\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1496\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1497\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1499\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_3/embedding_3/embedding_lookup' defined at (most recent call last):\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_cell\n      result = self._run_cell(\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n      return runner(coro)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3139, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3318, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/xx/tt65cl5915g65mpfmwy5nk8h0000gn/T/ipykernel_10534/3232910807.py\", line 1, in <module>\n      model, history = train_model(model = model,\n    File \"/var/folders/xx/tt65cl5915g65mpfmwy5nk8h0000gn/T/ipykernel_10534/4016102854.py\", line 113, in train_model\n      history = model.fit(X_pad,\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1218, in fit\n      val_logs = self.evaluate(\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1497, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1327, in test_function\n      return step_function(self, iterator)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1318, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1311, in run_step\n      outputs = model.test_step(data)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 1270, in test_step\n      y_pred = self(x, training=False)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1044, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\", line 379, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\", line 419, in call\n      return self._run_internal_graph(\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\", line 555, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1044, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/Users/timcerta/.pyenv/versions/3.8.12/envs/xref/lib/python3.8/site-packages/tensorflow/python/keras/layers/embeddings.py\", line 191, in call\n      out = embedding_ops.embedding_lookup_v2(self.embeddings, inputs)\nNode: 'sequential_3/embedding_3/embedding_lookup'\nindices[3,122] = 4365 is not in [0, 4365)\n\t [[{{node sequential_3/embedding_3/embedding_lookup}}]] [Op:__inference_test_function_3758]"
     ]
    }
   ],
   "source": [
    "model, history = train_model(model = model,\n",
    "                X_pad = data_tokenized,\n",
    "                y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829dc3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d056ad86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('xref')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "5de49888c34cc98682ba707a14312ef22222df4f8946f096549f7af996c677f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
